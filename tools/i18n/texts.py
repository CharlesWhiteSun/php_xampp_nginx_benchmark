"""Internationalization texts for report generation."""

TEXTS = {
    "en": {
        "lang": "en",
        "title": "PHP Benchmark Report",
        "meta_generated": "Generated",
        "meta_source": "Source",
        "formulas_title": "Formulas",
        "formula_throughput": "Throughput: $R = \\frac{N}{T}$, where $N$ is total requests and $T$ is test duration.",
        "formula_percentile": "Percentile latency: $P_{90}$ means 90% of requests complete in $\\le P_{90}$.",
        "formula_delta": "Throughput delta: $\\Delta\\% = \\frac{R_{xampp} - R_{nginx}}{R_{nginx}} \\times 100\\%$.",
        "chart_requests": "Requests/sec by Endpoint",
        "desc_requests": "Shows throughput per endpoint across two systems. Compare XAMPP (constrained) and NGINX to see throughput differences.",
        "chart_latency": "Latency (ms) by Endpoint",
        "desc_latency": "Shows average response time across both systems. Lower bars are better. NGINX demonstrates multi-core potential; XAMPP is single-process control.",
        "chart_transfer": "Transfer (KB/sec) by Endpoint",
        "desc_transfer": "Shows output bandwidth per endpoint. Higher bars indicate more data served per second, useful for payload-heavy endpoints.",
        "chart_pctl": "Latency Percentiles (ms)",
        "desc_pctl": "Shows tail latency across both systems. Use P90 and P99 to understand worst-case behavior; lower values mean fewer slow requests.",
        "pctl_missing": "Percentile data is missing. Re-run the benchmark with latency percentiles enabled.",
        "chart_dist": "Requests/sec Distribution",
        "desc_dist": "Shows the spread of throughput across endpoints and systems. The violin width indicates density; compare central tendency between servers.",
        "chart_delta": "Throughput Comparison",
        "desc_delta": "Two system comparison: XAMPP (orange) and NGINX Multi-core (blue). Compare performance across all test endpoints.",
        "insights_title": "Insights",
        "interpretation_title": "Interpretation",
        "raw_title": "Raw Results",
        "test_values_title": "Benchmark Test Values",
        "performance_analysis_section": "Performance Analysis",
        "desc_performance_analysis": "Comprehensive visual analysis of benchmark performance metrics across all endpoints. Interactive charts showing throughput, latency, data transfer, and statistical distributions.",
        "th_timestamp": "Timestamp",
        "th_server": "Server",
        "th_endpoint": "Endpoint",
        "th_req": "Req/sec",
        "th_latency": "Latency",
        "th_p50": "P50",
        "th_p90": "P90",
        "th_p99": "P99",
        "th_transfer": "Transfer/sec",
        "th_winner_throughput": "Throughput Winner",
        "th_winner_throughput_improved": "Better Throughput",
        "th_delta": "Delta (%)",
        "th_winner_latency": "Latency Winner",
        "th_latency_delta": "Latency Delta (%)",
        "delta_yaxis": "Delta % (XAMPP vs NGINX Multi)",
        "no_pctl_chart": "No percentile series available.",
        "indicators_title": "Performance Indicators",
        "endpoint_analysis_title": "Endpoint Analysis",
        "interp_intro": "Use throughput and latency together to avoid a misleading single-metric conclusion.",
        "interp_compare": "Throughput favors {req_winner}; latency favors {lat_winner}.",
        "interp_tradeoff": "If your workload is batch or high concurrency, pick the throughput winner. If it is interactive, pick the latency winner.",
        "interp_consistent": "Both key metrics favor {winner}; it is the safer default for this workload.",
        "interp_tail": "High P99 indicates some requests will be significantly slower. If your application prioritizes response time (e.g., API or frontend services), consider choosing a setup with lower tail latency.",
        "interp_p99_missing": "P99 is missing; rerun benchmark with latency percentiles to validate tail behavior.",
        
        # CPU-specific interpretations
        "interp_cpu_winner": "{winner} excels at CPU-bound workloads.",
        "interp_cpu_nginx_wins": "NGINX's multi-core architecture leverages parallel processing, making it ideal for CPU-intensive applications like analytics, data processing, or scientific computing. The throughput advantage demonstrates superior scalability.",
        "interp_cpu_xampp_wins": "XAMPP's competitive CPU performance indicates efficient single-process optimization. This suggests the workload may not need multi-core scaling, or Apache's configuration is well-optimized for this task.",
        "interp_cpu_tradeoff": "CPU-heavy workloads benefit significantly from multi-core systems. If throughput is your priority, choose {req_winner}. If you need predictable latency for interactive applications, evaluate {lat_winner}.",
        "interp_cpu_consistent": "Both metrics favor {winner}, indicating comprehensive CPU efficiency. Recommended for applications requiring both high throughput and responsive performance.",
        
        # I/O-specific interpretations
        "interp_io_winner": "{winner} handles I/O-bound operations more efficiently.",
        "interp_io_xampp_wins": "XAMPP's superior I/O performance is notable—this may reflect optimized disk caching, efficient connection pooling, or Apache's proven stability with database workloads. Ideal for database-heavy applications.",
        "interp_io_nginx_wins": "NGINX's strong I/O throughput combined with PHP-FPM demonstrates its ability to handle concurrent I/O operations. This is typical for high-traffic services with database queries or file operations.",
        "interp_io_tradeoff": "I/O patterns vary significantly by application. For high-concurrency batch processing, choose {req_winner}. For interactive database queries requiring low latency, choose {lat_winner}.",
        "interp_io_consistent": "Both metrics favor {winner}, making it the recommended choice for mixed I/O workloads including databases and file operations.",
        "interp_io_context": "I/O performance is heavily influenced by disk subsystem and external services. These results reflect system-level I/O efficiency.",
        
        # JSON-specific interpretations
        "interp_json_winner": "{winner} is the better choice for JSON processing.",
        "interp_json_nginx_wins": "NGINX's advantage in JSON workloads reflects its efficiency in request serialization and payload handling. Critical for modern REST APIs and real-time data services.",
        "interp_json_xampp_wins": "XAMPP's competitive JSON performance suggests well-optimized serialization, making it suitable for REST API backends or SPA servers with moderate payload sizes.",
        "interp_json_tradeoff": "JSON serialization affects API responsiveness directly. Choose {req_winner} for high-throughput API gateways; choose {lat_winner} for latency-sensitive frontend services.",
        "interp_json_consistent": "Both metrics favor {winner}, indicating exceptional capability for JSON-heavy applications like REST APIs, GraphQL servers, or real-time feeds.",
        "interp_json_context": "JSON performance impacts user experience in modern web applications. These results are critical for API development decisions.",
        
        "endpoints_title": "Methodology",
        "endpoints_intro": "",
        "endpoint_cpu_title": "CPU",
        "endpoint_cpu_desc": "<table style='width:100%; border-collapse:collapse;'><tr><td style='padding:4px 0; color:var(--text); font-weight:600; width:88px;'>Purpose</td><td style='padding:4px 0;'>Measure pure computational throughput and CPU efficiency.</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>Use Case</td><td style='padding:4px 0;'>Compute-heavy processing pipelines and algorithmic services.</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>Metric Meaning</td><td style='padding:4px 0;'>Shows how effectively architecture handles CPU-bound saturation.</td></tr></table>",
        "endpoint_io_title": "I/O",
        "endpoint_io_desc": "<table style='width:100%; border-collapse:collapse;'><tr><td style='padding:4px 0; color:var(--text); font-weight:600; width:88px;'>Purpose</td><td style='padding:4px 0;'>Simulate disk/database wait behavior under concurrent traffic.</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>Use Case</td><td style='padding:4px 0;'>Data-access services with file/database/API interactions.</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>Metric Meaning</td><td style='padding:4px 0;'>Reflects queueing efficiency and stability during I/O contention.</td></tr></table>",
        "endpoint_json_title": "JSON",
        "endpoint_json_desc": "<table style='width:100%; border-collapse:collapse;'><tr><td style='padding:4px 0; color:var(--text); font-weight:600; width:88px;'>Purpose</td><td style='padding:4px 0;'>Evaluate serialization/deserialization throughput and payload handling.</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>Use Case</td><td style='padding:4px 0;'>API gateways, SPA backends, and real-time data responses.</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>Metric Meaning</td><td style='padding:4px 0;'>Indicates dynamic response generation efficiency at scale.</td></tr></table>",
        "endpoint_name": "Endpoint Name",
        "endpoint_workload": "Workload Type",
        "endpoint_use_case": "Use Case & Scenario",
        "endpoint_description": "Technical Details & Purpose",
        "endpoint_method": "Testing Methodology",
        "endpoint_cpu_workload": "Compute-intensive",
        "endpoint_json_workload": "Serialization-intensive",
        "endpoint_io_workload": "I/O-intensive",
        "endpoint_cpu_usecase": "<div>．Computational analysis</div><div>．Data processing</div><div>．Analytics engines</div><div>．Algorithmic workloads</div>",
        "endpoint_cpu_method": "<div>．Iterative mathematical computation</div><div>．No external I/O path</div><div>．Vary iteration counts for stress scaling</div>",
        "endpoint_json_usecase": "<div>．REST APIs</div><div>．Real-time feeds</div><div>．SPA backends</div><div>．Middleware serialization</div>",
        "endpoint_json_method": "<div>．JSON encode/decode cycle test</div><div>．Payload size variation</div><div>．Serialization efficiency validation</div>",
        "endpoint_io_usecase": "<div>．Database applications</div><div>．File-based services</div><div>．Backend query pipelines</div><div>．Content management systems</div>",
        "endpoint_io_method": "<div>．Simulated file and memory I/O</div><div>．Variable block size pressure</div><div>．Iteration tuning for concurrency behavior</div>",
        "interp_metric": "Performance Indicator",
        "interp_evaluation": "What It Means",
        "interp_recommendations": "Implementation Recommendations",
        "interp_throughput": "Request Throughput (Req/sec)",
        "interp_throughput_eval": "Higher is better; reflects maximum capacity under load. Shows how many requests per second each system can process. Critical for capacity planning.",
        "interp_throughput_recommend": "<div>．Compare across endpoints to identify bottlenecks</div><div>．If throughput favors multi-core (NGINX), workload is parallelizable and benefits from scaling</div><div>．For batch processing or competitive APIs, prioritize the throughput winner</div>",
        "interp_latency": "Response Latency (Average ms)",
        "interp_latency_eval": "Lower is better; represents typical user experience. High average latency signals processing delays or contention. Affects perceived responsiveness in interactive applications.",
        "interp_latency_recommend": "<div>．Identify outlier endpoints and optimize them first</div><div>．If NGINX shows lower latency, its architecture is more efficient for this workload</div><div>．For interactive services (web UI, APIs), prioritize the latency winner and target <100ms average latency</div>",
        "interp_percentile": "Tail Latency (P90, P99 ms)",
        "interp_percentile_eval": "Critical for worst-case prediction; P99 tells you the slowest 1% of requests. High P99 indicates uneven performance and potential for user dissatisfaction.",
        "interp_percentile_recommend": "<div>．Keep P99 within 3x of average latency to maintain consistency</div><div>．If P99 is significantly high, investigate resource contention first</div><div>．For real-time or SLA-sensitive services, prioritize lower tail latency and monitor both P90 and P99</div>",
        "interp_transfer": "Data Transfer Rate (KB/sec)",
        "interp_transfer_eval": "Higher throughput in KB/sec indicates better network/I/O efficiency. Useful for payload-heavy endpoints or when bandwidth is a constraint.",
        "interp_transfer_recommend": "<div>．Compare transfer rates across endpoints; JSON usually carries more payload than CPU-only</div><div>．If one system is consistently lower, optimize the network handling path</div><div>．For data-intensive services, keep bandwidth headroom and avoid near-saturation operation</div>",
        "interp_consistency": "Performance Consistency & Stability",
        "interp_consistency_eval": "Compare variance in P50/P90/P99 across endpoints. If one system shows consistent performance, it's more predictable; if another is erratic, it may have per-request overhead or resource contention.",
        "interp_consistency_recommend": "<div>．Favor systems with tighter P90/P99 bounds for production stability</div><div>．Monitor both averages and percentiles because extremes matter for SLAs</div><div>．If variability is high, profile root causes such as GC pauses or thread contention</div>",
        "interp_endpoint_analysis": "Endpoint-Specific Analysis",
        "endpoint_name_short": "Endpoint",
        "interp_finding": "Key Finding",
        "interp_detail": "Detailed Analysis",
        "theme_label": "Theme:",
        "metric_high": "▲ Higher is better",
        "metric_low": "▼ Lower is better",
        "metric_compare": "⇄ Compare",
        
        # Summary section
        "summary_title": "Benchmark Configuration",
        "summary_intro": "This section explains not only the selected benchmark parameters, but also why these parameters matter, what they represent, and what decisions they support.",
        "summary_rationale_intro": "Use the table below to map each parameter to its design rationale and business value.",
        "summary_rationale_param": "Parameter",
        "summary_rationale_why": "Why This Setting",
        "summary_rationale_meaning": "What It Means in Results",
        "summary_rationale_goal": "Primary Goal",
        "summary_rationale_duration_why": "Defines the observation window so both short spikes and sustained behavior can be captured.",
        "summary_rationale_duration_meaning": "Longer duration better reflects stability and thermal/resource effects; shorter duration is better for quick regression checks.",
        "summary_rationale_duration_goal": "Balance confidence and execution time.",
        "summary_rationale_connections_why": "Simulates concurrent user pressure and queueing contention in realistic traffic conditions.",
        "summary_rationale_connections_meaning": "Higher concurrency stresses scheduler, worker pool, and lock/contention paths; reveals capacity ceilings.",
        "summary_rationale_connections_goal": "Measure throughput under load and identify bottlenecks.",
        "summary_rationale_endpoint_why": "Each endpoint models a different workload class: CPU-bound, serialization-heavy, and I/O-bound.",
        "summary_rationale_endpoint_meaning": "Separating workload types prevents misleading averages and pinpoints architecture strengths/weaknesses.",
        "summary_rationale_endpoint_goal": "Support workload-specific deployment decisions.",
        "summary_payload_group": "Benchmark Parameters",
        "params_title": "Benchmark Parameters",
        "params_intro": "Parameter Notes",
        "summary_rationale_payload_why": "Iteration counts and payload size control computational and data-transfer intensity.",
        "summary_rationale_payload_meaning": "Helps distinguish whether limits come from compute, memory, serialization, or I/O transfer paths.",
        "summary_rationale_payload_goal": "Improve tuning precision and optimization priority.",
        "summary_duration": "Test Duration",
        "summary_duration_unit": "seconds",
        "summary_connections": "Concurrent Connections",
        "summary_connections_unit": "threads",
        "summary_cpu_iter": "CPU Iterations",
        "summary_json_items": "JSON Items",
        "summary_io_size": "I/O Block Size",
        "summary_io_size_unit": "bytes",
        "summary_io_iter": "I/O Iterations",
        "summary_io_mode": "I/O Mode",
        "summary_endpoints": "Test Endpoints",
        "summary_test_time": "Test Timestamp",
    },
    "zh": {
        "lang": "zh-Hant",
        "title": "PHP 壓測報告",
        "meta_generated": "產生時間",
        "meta_source": "來源",
        "formulas_title": "公式",
        "formula_throughput": "吞吐量：$R = \\frac{N}{T}$，其中 $N$ 為總請求數，$T$ 為測試時間。",
        "formula_percentile": "延遲分位數：$P_{90}$ 表示 90% 的請求在 $\\le P_{90}$ 內完成。",
        "formula_delta": "吞吐差異：$\\Delta\\% = \\frac{R_{xampp} - R_{nginx}}{R_{nginx}} \\times 100\\%$。",
        "chart_requests": "每端點 Requests/sec",
        "desc_requests": "比較受壓測系統的各端點吞吐量",
        "chart_latency": "端點延遲 (ms)",
        "desc_latency": "比較受壓測系統的平均回應時間",
        "chart_transfer": "端點傳輸量 (KB/sec)",
        "desc_transfer": "比較受壓測系統的每秒傳輸量",
        "chart_pctl": "延遲分位數 (ms)",
        "desc_pctl": "比較受壓測系統的尾端延遲",
        "pctl_missing": "缺少分位數資料，請重新跑壓測以啟用延遲分位數模式。",
        "chart_dist": "Requests/sec 分佈",
        "desc_dist": "比較受壓測系統的吞吐量分佈，寬度代表密度",
        "chart_delta": "吞吐量對比",
        "desc_delta": "比較受壓測系統的各端點效能差異",
        "insights_title": "重點整理",
        "interpretation_title": "解讀建議",
        "raw_title": "原始結果",
        "test_values_title": "壓測數值",
        "performance_analysis_section": "視覺化圖表",
        "desc_performance_analysis": "",
        "th_timestamp": "時間",
        "th_server": "服務",
        "th_endpoint": "端點",
        "th_req": "Req/sec",
        "th_latency": "延遲",
        "th_p50": "P50",
        "th_p90": "P90",
        "th_p99": "P99",
        "th_transfer": "傳輸量/sec",
        "th_winner_throughput": "吞吐勝出",
        "th_winner_throughput_improved": "吞吐量較優",
        "th_delta": "差異 (%)",
        "th_winner_latency": "延遲勝出",
        "th_latency_delta": "延遲差異 (%)",
        "delta_yaxis": "差異 % (XAMPP 相對 NGINX)",
        "no_pctl_chart": "沒有分位數資料。",
        "indicators_title": "效能指標說明",
        "endpoint_analysis_title": "端點分析",
        "interp_intro": "建議同時看吞吐與延遲，避免只用單一指標做判斷。",
        "interp_compare": "吞吐偏向 {req_winner}；延遲偏向 {lat_winner}。",
        "interp_tradeoff": "若是批次或高併發工作，偏向吞吐勝出；若是互動型工作，偏向延遲勝出。",
        "interp_consistent": "兩項指標都偏向 {winner}，可作為此工作負載的優先選擇。",
        "interp_tail": "P99 明顯偏高，代表部分請求的延遲會特別久。若你的應用對響應速度要求高（如API/前端服務），應選擇尾端延遲更低的方案。",
        "interp_p99_missing": "缺少 P99，請重新跑壓測以確認尾端延遲。",
        
        # CPU-specific interpretations
        "interp_cpu_winner": "{winner} 在 CPU 密集型工作負載上表現卓越。",
        "interp_cpu_nginx_wins": "NGINX 的多核心架構充分利用並行處理能力，適合分析、數據處理或科學計算等 CPU 密集型應用。吞吐量優勢證明了其卓越的可擴展性。",
        "interp_cpu_xampp_wins": "XAMPP 的 CPU 性能具競爭力，表明單進程優化充分。這意味著該工作負載可能無需多核擴展，或 Apache 配置對此任務進行了良好最佳化。",
        "interp_cpu_tradeoff": "CPU 密集型工作負載從多核系統中獲益顯著。若優先考慮吞吐量，選擇 {req_winner}；若需要互動應用的可預測延遲，評估 {lat_winner}。",
        "interp_cpu_consistent": "兩項指標都偏向 {winner}，表示全面的 CPU 效率。建議用於同時需要高吞吐量與快速回應的應用。",
        
        # I/O-specific interpretations
        "interp_io_winner": "{winner} 在 I/O 密集型操作上表現更高效。",
        "interp_io_xampp_wins": "XAMPP 的 I/O 性能優異—這可能反映了優化的磁碟快取、高效的連接池管理，或 Apache 在資料庫工作負載上的穩定性優勢。適合資料庫密集型應用。",
        "interp_io_nginx_wins": "NGINX 強大的 I/O 吞吐量與 PHP-FPM 的結合展示了其處理併發 I/O 操作的能力。這是高流量服務（涉及資料庫查詢或文件操作）的典型表現。",
        "interp_io_tradeoff": "I/O 模式因應用而異。高併發批處理選 {req_winner}；互動式資料庫查詢需低延遲時選 {lat_winner}。",
        "interp_io_consistent": "兩項指標都偏向 {winner}，為混合型 I/O 工作負載（包括資料庫與檔案操作）的推薦選擇。",
        "interp_io_context": "I/O 性能深受磁碟子系統與外部服務影響。這些結果反映系統級 I/O 效率。",
        
        # JSON-specific interpretations
        "interp_json_winner": "{winner} 是 JSON 處理的更佳選擇。",
        "interp_json_nginx_wins": "NGINX 在 JSON 工作負載上的優勢體現了其請求序列化與 payload 處理的效率。對於現代 REST API 與即時數據服務至關重要。",
        "interp_json_xampp_wins": "XAMPP 具競爭力的 JSON 性能表明序列化最佳化充分，適合 REST API 後端或中等 payload 規模的 SPA 伺服器。",
        "interp_json_tradeoff": "JSON 序列化直接影響 API 回應速度。選 {req_winner} 用於高吞吐量 API 閘道；選 {lat_winner} 用於延遲敏感的前端服務。",
        "interp_json_consistent": "兩項指標都偏向 {winner}，表示對 JSON 密集型應用的卓越能力，如 REST API、GraphQL 伺服器或即時數據饋送。",
        "interp_json_context": "JSON 性能影響現代網路應用的用戶體驗。這些結果對 API 開發決策至關重要。",
        
        "endpoints_title": "設計方法",
        "endpoints_intro": "",
        "endpoint_cpu_title": "CPU",
        "endpoint_cpu_desc": "<table style='width:100%; border-collapse:collapse;'><tr><td style='padding:4px 0; color:var(--text); font-weight:600; width:64px;'>用途</td><td style='padding:4px 0;'>測量純運算吞吐量與 CPU 效率。</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>應用場景</td><td style='padding:4px 0;'>適合運算密集與演算法處理服務。</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>指標意義</td><td style='padding:4px 0;'>反映架構在 CPU 壓力下的擴展與穩定能力。</td></tr></table>",
        "endpoint_io_title": "I/O",
        "endpoint_io_desc": "<table style='width:100%; border-collapse:collapse;'><tr><td style='padding:4px 0; color:var(--text); font-weight:600; width:64px;'>用途</td><td style='padding:4px 0;'>模擬資料庫/檔案等待下的真實 I/O 行為。</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>應用場景</td><td style='padding:4px 0;'>資料存取型系統與外部服務整合場景。</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>指標意義</td><td style='padding:4px 0;'>觀察佇列處理效率與 I/O 競爭時的穩定性。</td></tr></table>",
        "endpoint_json_title": "JSON",
        "endpoint_json_desc": "<table style='width:100%; border-collapse:collapse;'><tr><td style='padding:4px 0; color:var(--text); font-weight:600; width:64px;'>用途</td><td style='padding:4px 0;'>測試序列化/反序列化與 payload 處理效率。</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>應用場景</td><td style='padding:4px 0;'>REST API、SPA 後端與即時資料回應。</td></tr><tr><td style='padding:4px 0; color:var(--text); font-weight:600;'>指標意義</td><td style='padding:4px 0;'>反映動態內容生成與資料傳輸效率。</td></tr></table>",
        "endpoint_name": "端點名稱",
        "endpoint_workload": "運算工作類型",
        "endpoint_use_case": "使用場景與應用",
        "endpoint_description": "技術細節與用途",
        "endpoint_method": "測試方法",
        "endpoint_cpu_workload": "運算密集型",
        "endpoint_json_workload": "序列化密集型",
        "endpoint_io_workload": "I/O 密集型",
        "endpoint_cpu_usecase": "<div>．運算分析</div><div>．資料處理</div><div>．分析引擎</div><div>．演算法工作負載</div>",
        "endpoint_cpu_method": "<div>．迭代數學運算</div><div>．不走外部 I/O 路徑</div><div>．調整迴圈次數進行壓力分級</div>",
        "endpoint_json_usecase": "<div>．REST API</div><div>．即時數據饋送</div><div>．SPA 後端</div><div>．中介層序列化</div>",
        "endpoint_json_method": "<div>．JSON 編碼/解碼循環</div><div>．Payload 大小變化測試</div><div>．驗證序列化處理效率</div>",
        "endpoint_io_usecase": "<div>．資料庫應用</div><div>．檔案型服務</div><div>．後端查詢流程</div><div>．內容管理系統</div>",
        "endpoint_io_method": "<div>．模擬檔案與記憶體 I/O</div><div>．變化區塊大小觀察壓力</div><div>．調整迴圈測試併發行為</div>",
        "interp_metric": "指標",
        "interp_evaluation": "含義解讀",
        "interp_recommendations": "實作建議",
        "interp_throughput": "請求吞吐量 (Req/sec)",
        "interp_throughput_eval": "越高越好；反映負載下的最大容量。顯示每秒能處理的請求數。對容量規劃至關重要。",
        "interp_throughput_recommend": "<div>．跨端點比較以找出瓶頸</div><div>．若多核心吞吐量領先，代表工作負載可並行化且受益於擴展</div><div>．批處理或高競爭 API，優先選吞吐勝出的方案</div>",
        "interp_latency": "回應延遲 (平均 ms)",
        "interp_latency_eval": "越低越好；代表典型使用者體驗。延遲高代表處理延遲或資源競爭。影響互動應用的回應速度。",
        "interp_latency_recommend": "<div>．找出異常端點並優先優化</div><div>．若 NGINX 延遲更低，表示其架構對此工作負載更高效</div><div>．互動式服務（網頁 UI、API）優先選延遲勝出者，目標平均延遲 < 100ms</div>",
        "interp_percentile": "尾端延遲 (P90, P99 ms)",
        "interp_percentile_eval": "對最壞情況預測至關重要；P99 反映最慢 1% 的請求。P99 偏高代表效能不均，可能導致使用者不滿。",
        "interp_percentile_recommend": "<div>．P99 建議維持在平均延遲的 3 倍內，以確保一致性</div><div>．P99 明顯偏高時，優先調查資源競爭與排隊瓶頸</div><div>．即時或 SLA 敏感應用應優先選擇尾端延遲更低方案，並同時監控 P90 / P99</div>",
        "interp_transfer": "資料傳輸速率 (KB/sec)",
        "interp_transfer_eval": "KB/sec 吞吐量越高表示網路/I/O 效率越好。對 payload 密集端點或頻寬受限情境尤其有用。",
        "interp_transfer_recommend": "<div>．跨端點比較傳輸量；JSON 通常比 CPU-only 傳輸更多資料</div><div>．若某系統傳輸速率持續偏低，優先優化網路處理路徑</div><div>．資料密集服務需預留頻寬裕度，避免接近飽和</div>",
        "interp_consistency": "效能一致性與穩定性",
        "interp_consistency_eval": "比較 P50/P90/P99 在端點間的變異。若某系統效能一致，更可預測；若另一系統不規律，可能存在每request 開銷或資源競爭。",
        "interp_consistency_recommend": "<div>．優先採用 P90/P99 邊界更緊密的系統，提高生產穩定性</div><div>．同時監控平均值與分位數，因為極值對 SLA 影響更大</div><div>．變異性高時，應分析根因（例如 GC 停頓、執行緒競爭）</div>",
        "interp_endpoint_analysis": "端點分析",
        "endpoint_name_short": "端點",
        "interp_finding": "關鍵發現",
        "interp_detail": "詳細分析",
        "theme_label": "佈景主題:",
        "metric_high": "▲ 高值較佳",
        "metric_low": "▼ 低值較佳",
        "metric_compare": "⇄ 比較指標",
        
        # Summary section
        "summary_title": "壓測配置",
        "summary_intro": "本節不只列出壓測參數，也進一步說明為何要這樣設定、這些定義在結果解讀上的意義，以及可支援哪些決策目標。",
        "summary_rationale_intro": "可透過下表快速理解每個參數的設計理由與實務價值。",
        "summary_rationale_param": "參數",
        "summary_rationale_why": "為何要這樣設定",
        "summary_rationale_meaning": "在結果中的解讀意義",
        "summary_rationale_goal": "可達成的主要目標",
        "summary_rationale_duration_why": "定義觀測時間窗，讓測試能同時涵蓋短期波動與持續負載行為。",
        "summary_rationale_duration_meaning": "時間較長更能反映穩定性與資源累積效應；時間較短則適合快速回歸驗證。",
        "summary_rationale_duration_goal": "在測試可信度與執行效率間取得平衡。",
        "summary_rationale_connections_why": "模擬真實併發使用者壓力，觀察排隊、競爭與資源飽和情況。",
        "summary_rationale_connections_meaning": "較高併發可放大排程、工作池與鎖競爭瓶頸，幫助識別容量上限。",
        "summary_rationale_connections_goal": "評估高負載下吞吐能力並定位瓶頸。",
        "summary_rationale_endpoint_why": "以 CPU、JSON、I/O 三類端點覆蓋不同工作負載特性，避免單一型態偏差。",
        "summary_rationale_endpoint_meaning": "分開觀察可更準確判斷架構優勢，不會被平均值掩蓋問題。",
        "summary_rationale_endpoint_goal": "支援依工作型態做部署與架構選型。",
        "summary_payload_group": "壓測參數",
        "params_title": "壓測參數",
        "params_intro": "參數說明",
        "summary_rationale_payload_why": "迴圈次數與資料量大小可控制運算強度與資料傳輸壓力。",
        "summary_rationale_payload_meaning": "有助區分瓶頸來源是 CPU、記憶體、序列化或 I/O 路徑。",
        "summary_rationale_payload_goal": "提升調校精準度與優化優先順序。",
        "summary_duration": "測試持續時間",
        "summary_duration_unit": "秒",
        "summary_connections": "並行連接數",
        "summary_connections_unit": "個執行緒",
        "summary_cpu_iter": "CPU 迴圈次數",
        "summary_json_items": "JSON 項目數",
        "summary_io_size": "I/O 區塊大小",
        "summary_io_size_unit": "位元組",
        "summary_io_iter": "I/O 迴圈次數",
        "summary_io_mode": "I/O 模式",
        "summary_endpoints": "測試端點",
        "summary_test_time": "測試時間戳",
    }
}

def get_text(lang: str) -> dict:
    """Get text dictionary for a specific language."""
    return TEXTS.get(lang, TEXTS.get("zh"))
